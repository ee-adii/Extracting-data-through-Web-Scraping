{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Web Scraping Basics"}, {"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "### If you want to srape a website \n### 1. use an API\n### 2. HTML web scraping using some tool\n#### we will use BeautifulSoup Library to extract data "}, {"metadata": {}, "cell_type": "code", "source": "import requests \nfrom bs4 import BeautifulSoup as bs", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "url = \"https://keithgalli.github.io/web-scraping/example.html\"", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### step 1: Get the HTML"}, {"metadata": {}, "cell_type": "code", "source": "r = requests.get(url)   ", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "htmlContent = r.content    ## geting content fron given url\n\nprint(htmlContent)", "execution_count": 5, "outputs": [{"output_type": "stream", "text": "b'<html>\\n<head>\\n<title>HTML Example</title>\\n</head>\\n<body>\\n\\n<div align=\"middle\">\\n<h1>HTML Webpage</h1>\\n<p>Link to more interesting example: <a href=\"https://keithgalli.github.io/web-scraping/webpage.html\">keithgalli.github.io/web-scraping/webpage.html</a></p>\\n</div>\\n\\n<h2>A Header</h2>\\n<p><i>Some italicized text</i></p>\\n\\n<h2>Another header</h2>\\n<p id=\"paragraph-id\"><b>Some bold text</b></p>\\n\\n</body>\\n</html>\\n'\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### step 2: Parse the HTML"}, {"metadata": {"scrolled": false}, "cell_type": "code", "source": "soup =  bs(htmlContent , 'html.parser')\n##print(soup)\nprint(soup.prettify())", "execution_count": 6, "outputs": [{"output_type": "stream", "text": "<html>\n <head>\n  <title>\n   HTML Example\n  </title>\n </head>\n <body>\n  <div align=\"middle\">\n   <h1>\n    HTML Webpage\n   </h1>\n   <p>\n    Link to more interesting example:\n    <a href=\"https://keithgalli.github.io/web-scraping/webpage.html\">\n     keithgalli.github.io/web-scraping/webpage.html\n    </a>\n   </p>\n  </div>\n  <h2>\n   A Header\n  </h2>\n  <p>\n   <i>\n    Some italicized text\n   </i>\n  </p>\n  <h2>\n   Another header\n  </h2>\n  <p id=\"paragraph-id\">\n   <b>\n    Some bold text\n   </b>\n  </p>\n </body>\n</html>\n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "###  BeautifulSoup Methods\n####  1. find and find_all methods"}, {"metadata": {}, "cell_type": "code", "source": "first_header = soup.find(\"h1\")   \nprint(first_header)", "execution_count": 16, "outputs": [{"output_type": "stream", "text": "<h1>HTML Webpage</h1>\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "print(soup.h1)   ## without using find to get \"h1\" tag", "execution_count": 17, "outputs": [{"output_type": "stream", "text": "<h1>HTML Webpage</h1>\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "ll = soup.find_all(\"a\")\nll     ## to get all anchors ie \"a\" tag", "execution_count": 18, "outputs": [{"output_type": "execute_result", "execution_count": 18, "data": {"text/plain": "[<a href=\"https://keithgalli.github.io/web-scraping/webpage.html\">keithgalli.github.io/web-scraping/webpage.html</a>]"}, "metadata": {}}]}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "headers = soup.find(['h1' , 'h2' ])\nheaders    ## to get specific headers", "execution_count": 19, "outputs": [{"output_type": "execute_result", "execution_count": 19, "data": {"text/plain": "<h1>HTML Webpage</h1>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "## for geting a para\nparas = soup.find('p')\nparas\n", "execution_count": 20, "outputs": [{"output_type": "execute_result", "execution_count": 20, "data": {"text/plain": "<p>Link to more interesting example: <a href=\"https://keithgalli.github.io/web-scraping/webpage.html\">keithgalli.github.io/web-scraping/webpage.html</a></p>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "all_para = soup.find_all('p')\nall_para                        ## print all paragraphs \nall_para = list(all_para)       ## converting to list \nall_para\nall_para[1]", "execution_count": 21, "outputs": [{"output_type": "execute_result", "execution_count": 21, "data": {"text/plain": "<p><i>Some italicized text</i></p>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "## narrowing down the scraping\n\nbdy = soup.find(\"body\")\nbdy", "execution_count": 22, "outputs": [{"output_type": "execute_result", "execution_count": 22, "data": {"text/plain": "<body>\n<div align=\"middle\">\n<h1>HTML Webpage</h1>\n<p>Link to more interesting example: <a href=\"https://keithgalli.github.io/web-scraping/webpage.html\">keithgalli.github.io/web-scraping/webpage.html</a></p>\n</div>\n<h2>A Header</h2>\n<p><i>Some italicized text</i></p>\n<h2>Another header</h2>\n<p id=\"paragraph-id\"><b>Some bold text</b></p>\n</body>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "## looking for div within the body\ndiv = bdy.find('div')\ndiv", "execution_count": 27, "outputs": [{"output_type": "execute_result", "execution_count": 27, "data": {"text/plain": "<div align=\"middle\">\n<h1>HTML Webpage</h1>\n<p>Link to more interesting example: <a href=\"https://keithgalli.github.io/web-scraping/webpage.html\">keithgalli.github.io/web-scraping/webpage.html</a></p>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "## looking for button within div\n## so we are traversing the html tree\nbtn = div.find('button')\nbtn\n", "execution_count": 50, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Select (CSS selector)"}, {"metadata": {}, "cell_type": "code", "source": "body = soup.body\nprint(body.prettify())\n", "execution_count": 31, "outputs": [{"output_type": "stream", "text": "<body>\n <div align=\"middle\">\n  <h1>\n   HTML Webpage\n  </h1>\n  <p>\n   Link to more interesting example:\n   <a href=\"https://keithgalli.github.io/web-scraping/webpage.html\">\n    keithgalli.github.io/web-scraping/webpage.html\n   </a>\n  </p>\n </div>\n <h2>\n  A Header\n </h2>\n <p>\n  <i>\n   Some italicized text\n  </i>\n </p>\n <h2>\n  Another header\n </h2>\n <p id=\"paragraph-id\">\n  <b>\n   Some bold text\n  </b>\n </p>\n</body>\n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "cnt  = soup.select('p')  ## similar to find_all\ncnt  ## returns a list of 'p'\ncnt[1]", "execution_count": 32, "outputs": [{"output_type": "execute_result", "execution_count": 32, "data": {"text/plain": "<p><i>Some italicized text</i></p>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "## looking for paras in div (this way we can easily norrow down our scrap)\ndiv_p = soup.select('div p')     ### soup.select('parent child subchild _ _so on')\ndiv_p          ## we can also print it by traversing like a tree as \"div.p\"", "execution_count": 33, "outputs": [{"output_type": "execute_result", "execution_count": 33, "data": {"text/plain": "[<p>Link to more interesting example: <a href=\"https://keithgalli.github.io/web-scraping/webpage.html\">keithgalli.github.io/web-scraping/webpage.html</a></p>]"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "p_nextto_h2 = soup.select('h2 ~p')\np_nextto_h2  ## geting para just after the h2", "execution_count": 34, "outputs": [{"output_type": "execute_result", "execution_count": 34, "data": {"text/plain": "[<p><i>Some italicized text</i></p>,\n <p id=\"paragraph-id\"><b>Some bold text</b></p>]"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "paras  = soup.select(\"body p\")\nparas\n", "execution_count": 35, "outputs": [{"output_type": "execute_result", "execution_count": 35, "data": {"text/plain": "[<p>Link to more interesting example: <a href=\"https://keithgalli.github.io/web-scraping/webpage.html\">keithgalli.github.io/web-scraping/webpage.html</a></p>,\n <p><i>Some italicized text</i></p>,\n <p id=\"paragraph-id\"><b>Some bold text</b></p>]"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "paras  = soup.select(\"body >p\")\nparas   ## direct approach the decendent ", "execution_count": 36, "outputs": [{"output_type": "execute_result", "execution_count": 36, "data": {"text/plain": "[<p><i>Some italicized text</i></p>,\n <p id=\"paragraph-id\"><b>Some bold text</b></p>]"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Grabbing the text/String"}, {"metadata": {}, "cell_type": "code", "source": "\nhdr  = soup.find(\"h1\")\nhdr                    ## this gives me whole tag h1", "execution_count": 38, "outputs": [{"output_type": "execute_result", "execution_count": 38, "data": {"text/plain": "<h1>HTML Webpage</h1>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "hdr.string            ## geting only string from tag h1", "execution_count": 41, "outputs": [{"output_type": "execute_result", "execution_count": 41, "data": {"text/plain": "'HTML Webpage'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "## when multiple string present in a tag then use \"get_text\" method\n\n\ndiv = soup.find('div')\ndiv\nprint(div.prettify())", "execution_count": 45, "outputs": [{"output_type": "stream", "text": "<div align=\"middle\">\n <h1>\n  HTML Webpage\n </h1>\n <p>\n  Link to more interesting example:\n  <a href=\"https://keithgalli.github.io/web-scraping/webpage.html\">\n   keithgalli.github.io/web-scraping/webpage.html\n  </a>\n </p>\n</div>\n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "all_text = div.get_text()\nprint(all_text)        ## geting all the text in div ", "execution_count": 52, "outputs": [{"output_type": "stream", "text": "\nHTML Webpage\nLink to more interesting example: keithgalli.github.io/web-scraping/webpage.html\n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## finding Parent , Child, Siblings\n"}, {"metadata": {}, "cell_type": "code", "source": "print(soup.prettify())", "execution_count": 58, "outputs": [{"output_type": "stream", "text": "<html>\n <head>\n  <title>\n   HTML Example\n  </title>\n </head>\n <body>\n  <div align=\"middle\">\n   <h1>\n    HTML Webpage\n   </h1>\n   <p>\n    Link to more interesting example:\n    <a href=\"https://keithgalli.github.io/web-scraping/webpage.html\">\n     keithgalli.github.io/web-scraping/webpage.html\n    </a>\n   </p>\n  </div>\n  <h2>\n   A Header\n  </h2>\n  <p>\n   <i>\n    Some italicized text\n   </i>\n  </p>\n  <h2>\n   Another header\n  </h2>\n  <p id=\"paragraph-id\">\n   <b>\n    Some bold text\n   </b>\n  </p>\n </body>\n</html>\n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "\ndiv = soup.div\n\nprint(div.prettify())\n\n", "execution_count": 62, "outputs": [{"output_type": "stream", "text": "<div align=\"middle\">\n <h1>\n  HTML Webpage\n </h1>\n <p>\n  Link to more interesting example:\n  <a href=\"https://keithgalli.github.io/web-scraping/webpage.html\">\n   keithgalli.github.io/web-scraping/webpage.html\n  </a>\n </p>\n</div>\n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "### geting next siblings of div\n\ndiv_siblings = div.find_next_siblings()\nprint(div_siblings)   ## returns the list of all siblings of div in HTML tree", "execution_count": 64, "outputs": [{"output_type": "stream", "text": "[<h2>A Header</h2>, <p><i>Some italicized text</i></p>, <h2>Another header</h2>, <p id=\"paragraph-id\"><b>Some bold text</b></p>]\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": " ## geting parent of div which is the body tag\n\ndiv_parent = div.find_parent()\nprint(div_parent.prettify())  ", "execution_count": 66, "outputs": [{"output_type": "stream", "text": "<body>\n <div align=\"middle\">\n  <h1>\n   HTML Webpage\n  </h1>\n  <p>\n   Link to more interesting example:\n   <a href=\"https://keithgalli.github.io/web-scraping/webpage.html\">\n    keithgalli.github.io/web-scraping/webpage.html\n   </a>\n  </p>\n </div>\n <h2>\n  A Header\n </h2>\n <p>\n  <i>\n   Some italicized text\n  </i>\n </p>\n <h2>\n  Another header\n </h2>\n <p id=\"paragraph-id\">\n  <b>\n   Some bold text\n  </b>\n </p>\n</body>\n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### ~ Aditya Mathur"}, {"metadata": {}, "cell_type": "markdown", "source": "#### source - Keith Galli"}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.8", "language": "python"}, "language_info": {"name": "python", "version": "3.8.12", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}